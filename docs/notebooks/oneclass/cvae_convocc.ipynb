{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "121ba1c5-d988-4546-b8f3-54324a5c341e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import umap\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from deeptime.models.representation import ConvVariationalAutoEncoder\n",
    "from deeptime.data import BaseDataset\n",
    "from deeptime.models.utils import Conv1dSamePadding, UpSample\n",
    "\n",
    "from sktime.datasets import load_UCR_UEA_dataset\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee45181-035e-42b1-9a76-cb74b885058f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvVAEOCC(pl.LightningModule):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        in_features: int,\n",
    "        latent_dim: int,\n",
    "        learning_rate: float = 5e-6,\n",
    "        radius: float = 0.\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.in_features = in_features\n",
    "        self.latent_dim = latent_dim\n",
    "        \n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        self.radius = radius\n",
    "        \n",
    "        self.e = nn.Sequential(\n",
    "            Conv1dSamePadding(\n",
    "                in_channels=in_channels,\n",
    "                out_channels=128,\n",
    "                kernel_size=8,\n",
    "                stride=1,\n",
    "                bias=False,\n",
    "            ),\n",
    "            nn.BatchNorm1d(num_features=128),\n",
    "            nn.Tanh(),\n",
    "            Conv1dSamePadding(\n",
    "                in_channels=128,\n",
    "                out_channels=256,\n",
    "                kernel_size=5,\n",
    "                stride=1,\n",
    "                bias=False,\n",
    "            ),\n",
    "            nn.BatchNorm1d(num_features=256),\n",
    "            nn.Tanh(),\n",
    "            Conv1dSamePadding(\n",
    "                in_channels=256,\n",
    "                out_channels=128,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                bias=False,\n",
    "            ),\n",
    "            nn.BatchNorm1d(num_features=256),\n",
    "            nn.Tanh(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=128 * in_features, out_features=256, bias=False),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(in_features=256, out_features=128, bias=False),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(in_features=128, out_features=latent_dim * 2, bias=False),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "        \n",
    "    def reparametrize(self, mu: torch.Tensor, log_var: torch.Tensor) -> torch.Tensor:\n",
    "        std = torch.exp(0.5 * log_var)\n",
    "        eps = torch.randn_like(std)\n",
    "        sample = mu + (eps * std)\n",
    "        return sample\n",
    "    \n",
    "    def forward(self, "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
