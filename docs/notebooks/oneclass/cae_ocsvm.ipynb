{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4028144-76fd-4743-9254-3bfec95dedeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from deeptime.models.representation import ConvAutoEncoder\n",
    "from deeptime.data import BaseDataset\n",
    "\n",
    "from sktime.datasets import load_UCR_UEA_dataset\n",
    "\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f52b31f-4cbf-4096-8c04-2e067a7f671b",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASETS = [\n",
    "    'Yoga',\n",
    "    # 'WormsTwoClass',\n",
    "    # 'Wine',\n",
    "    # 'Wafer',\n",
    "    # 'TwoLeadECG',\n",
    "    # 'Strawberry',\n",
    "    # 'SemgHandGenderCh2', \n",
    "    # 'BeetleFly',\n",
    "    # 'BirdChicken',\n",
    "    # 'Computers',\n",
    "    # 'DistalPhalanxOutlineCorrect',\n",
    "    # 'Earthquakes',\n",
    "    # 'ECG200',\n",
    "    # 'ECGFiveDays',\n",
    "    # 'FordA',\n",
    "    # 'FordB',\n",
    "    # 'HandOutlines',\n",
    "    # 'ItalyPowerDemand', \n",
    "    # 'MiddlePhalanxOutlineCorrect',\n",
    "    # 'Chinatown',\n",
    "    # 'FreezerRegularTrain',\n",
    "    # 'FreezerSmallTrain',\n",
    "    # 'GunPointAgeSpan',\n",
    "    # 'GunPointMaleVersusFemale',\n",
    "    # 'GunPointOldVersusYoung',\n",
    "    # 'PowerCons',\n",
    "    # 'Coffee',\n",
    "    # 'Ham',\n",
    "    # 'Herring',\n",
    "    # 'Lightning2',\n",
    "    # 'MoteStrain',\n",
    "    # 'PhalangesOutlinesCorrect',\n",
    "    # 'ProximalPhalanxOutlineCorrect',\n",
    "    # 'ShapeletSim',\n",
    "    # 'SonyAIBORobotSurface1',\n",
    "    # 'SonyAIBORobotSurface2',\n",
    "    # 'ToeSegmentation1',\n",
    "    # 'ToeSegmentation2',\n",
    "    # 'HouseTwenty'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5607f32-5e03-4525-b9d9-93d36805a036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tDownloading the Yoga dataset...\n",
      "\t\tDownload completed!\n",
      "\tTransforming data to the correct format...\n",
      "\t\tTransform completed!\n",
      "\tStarting the classifier...\n",
      "\t\tClassifying the label 1...\n",
      "\t\tReport:\n",
      "\t\t\tF1 Score = 0.6114920785055569\n",
      "\t\tClassifying the label 2...\n",
      "\t\tReport:\n",
      "\t\t\tF1 Score = 0.6945757371145622\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for dataset in DATASETS:\n",
    "    print(f'\\tDownloading the {dataset} dataset...')\n",
    "    x_train, y_train = load_UCR_UEA_dataset(name=dataset, split='train')\n",
    "    # Since the features from the sktime are instatiated as objects we have to manually convert them\n",
    "    y_train = np.array(y_train, dtype=np.int32)\n",
    "\n",
    "    sequence_length = x_train.values[0][0].shape[0]\n",
    "\n",
    "    x_test, y_test = load_UCR_UEA_dataset(name=dataset, split='test')\n",
    "    y_test = np.array(y_test, dtype='int32') # Fixing the labels type\n",
    "    print(f'\\t\\tDownload completed!')\n",
    "\n",
    "    print('\\tTransforming data to the correct format...')\n",
    "    x_train_transformed = []\n",
    "    for val in x_train.values:\n",
    "        x_train_transformed.append(val[0].tolist())\n",
    "    x_train = np.array(x_train_transformed)\n",
    "\n",
    "    x_test_transformed = []\n",
    "    for val in x_test.values:\n",
    "        x_test_transformed.append(val[0].tolist())\n",
    "    x_test = np.array(x_test_transformed)\n",
    "    \n",
    "    x_train = np.expand_dims(x_train_transformed, axis=1)\n",
    "    x_test = np.expand_dims(x_test_transformed, axis=1)\n",
    "    print('\\t\\tTransform completed!')\n",
    "\n",
    "    print('\\tStarting the classifier...')\n",
    "    unique_labels = np.unique(y_train)\n",
    "\n",
    "    model = ConvAutoEncoder(\n",
    "        in_channels=1,\n",
    "        in_features=sequence_length,\n",
    "        latent_dim=32,\n",
    "    )\n",
    "\n",
    "    model.load_state_dict(\n",
    "        torch.load(f'../../../pretrain/representation/{dataset}/conv_autoencoder.pt')\n",
    "    )\n",
    "\n",
    "    for label in unique_labels:\n",
    "        print(f'\\t\\tClassifying the label {label}...')\n",
    "        \n",
    "        x_train_ = x_train[y_train == label]\n",
    "        y_train_ = y_train[y_train == label]\n",
    "\n",
    "        occ_labels = [1 if x == label else -1 for x in y_test]\n",
    "\n",
    "        train_dataset = BaseDataset(x=x_train, y=y_train)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=32)\n",
    "        \n",
    "        representations = []\n",
    "        for x, y in train_loader:\n",
    "            x_hat, z = model(x)\n",
    "            representations.extend(z.tolist())\n",
    "\n",
    "        representations = np.array(representations)\n",
    "        # print(representations.shape)\n",
    "        # representations = representations.reshape((representations.shape[0], representations.shape[2]))\n",
    "\n",
    "        clf = OneClassSVM(gamma='scale', nu=0.1, kernel='rbf').fit(representations)\n",
    "        \n",
    "        test_dataset = BaseDataset(x=x_test, y=y_test)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=32)\n",
    "\n",
    "        test_representations = []\n",
    "\n",
    "        for x, y in test_loader:\n",
    "            x_hat, z = model(x)\n",
    "            test_representations.extend(z.tolist())\n",
    "\n",
    "        test_representations = np.array(test_representations)\n",
    "        # test_representations = test_representations.reshape((test_representations.shape[0], test_representations.shape[2]))\n",
    "\n",
    "        result_labels = clf.predict(test_representations)\n",
    "        \n",
    "        print(f'\\t\\tReport:')\n",
    "        # print(f'\\t\\t\\tAccuracy Score = {accuracy_score(occ_labels, result_labels)}')\n",
    "        print(f'\\t\\t\\tF1 Score = {f1_score(occ_labels, result_labels)}')\n",
    "\n",
    "    print('-' * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2d6ad4-585a-431c-bbc9-5b6245b65602",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
